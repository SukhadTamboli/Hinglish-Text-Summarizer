{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SukhadTamboli/Hinglish-Text-Summarizer/blob/main/translator_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRANSLATOR**\n",
        "Works with the use of google translator where we have used the library googletrans and further it shows which language is given and in which language we have translated to. \n",
        "Best thing here is it accepts hindi language through written in English alphabets.\n",
        "*Here the only problem is we have to give small amount of packet of data . So we have to bascillay break the whole document/text into sentences and then supply to the model.\n",
        "*Best thing is it have very high accuracy as you will see in the following example"
      ],
      "metadata": {
        "id": "QxYPuUzKgXKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6viF_jI0Szfe",
        "outputId": "4ef3155c-6979-4918-949a-d69bbfdbc844"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.9.24)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "  Downloading hstspreload-2022.11.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=1ba08e93f2a9d5837ce5dfc71c16d51417e53ddf66b2346c2414a5b21f82c90a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2022.11.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator , constants\n",
        "from pprint import pprint\n",
        "from fnmatch import translate"
      ],
      "metadata": {
        "id": "noMqGtWwSUf0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init the Google API translator\n",
        "translator = Translator()"
      ],
      "metadata": {
        "id": "NL58LaNESZ58"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Aaap konse college me education lete ho\",\n",
        "    \"aapka name kya hai?\",\n",
        "    \"Me abhi filhal engineering ke goes to college on 'Palaj' road\",\n",
        "    \"yeh tho biographical movie ke tarah hein, mark zukerberk ke baare mein hein kya\", \n",
        "    \"jo facebook create kiya haan yar. mein bhi is movie ke baare mein suna hoon, kahi saal ke pehle aaya tha na.\",\n",
        "    \"Rotten Tomatoes ne toh 96% deya tha aur yeh movie tho 2010 ka hein\"\n",
        "]\n",
        "translations = translator.translate(sentences, dest=\"en\")\n",
        "for translation in translations:\n",
        "    print(f\"{translation.origin} ({translation.src}) -->\\n {translation.text} ({translation.dest})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd2uS1WvVRXH",
        "outputId": "ffb716d1-ff06-408f-d40f-c7ace508a075"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aaap konse college me education lete ho (hi) -->\n",
            " In which college do you take education? (en)\n",
            "aapka name kya hai? (hi) -->\n",
            " What is your name? (en)\n",
            "Me abhi filhal engineering ke goes to college on 'Palaj' road (hi) -->\n",
            " I am currently going to engineering colleges on 'Palaj' road (en)\n",
            "yeh tho biographical movie ke tarah hein, mark zukerberk ke baare mein hein kya (hi) -->\n",
            " It's like a biographical movie about Mark Zuckerburk (en)\n",
            "jo facebook create kiya haan yar. mein bhi is movie ke baare mein suna hoon, kahi saal ke pehle aaya tha na. (hi) -->\n",
            " Who created Facebook yes man. I have also heard about this movie, it came a year ago, didn't it? (en)\n",
            "Rotten Tomatoes ne toh 96% deya tha aur yeh movie tho 2010 ka hein (hi) -->\n",
            " Rattan Tomatoes gave Toh 96% and this movie is from Tho 2010 (en)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \" @narendramodi great congratulations Sir,  ap ko Bharat Mata ne bheja\", \n",
        "    \"As an avtar like Lord Krishna and Ram, desh ke Kalman ke liye.\", \n",
        "    \"Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world Top in position.\"\n",
        "]\n",
        "translations = translator.translate(sentences, dest=\"en\")\n",
        "for translation in translations:\n",
        "    print(f\"{translation.origin} ({translation.src}) -->\\n {translation.text} ({translation.dest})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH2Nu7ryutSH",
        "outputId": "9ec3a9c2-331d-4214-9c95-4364966f880c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " @narendramodi great congratulations Sir,  ap ko Bharat Mata ne bheja (hi) -->\n",
            " @narendramodi great congress sir, you were sent by mother India (en)\n",
            "As an avtar like Lord Krishna and Ram, desh ke Kalman ke liye. (hi) -->\n",
            " Lord Krishna and Ram wrote Asan Avatar, for the welfare of the country. (en)\n",
            "Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world Top in position. (bn) -->\n",
            " Saos krode desh bashio ki umid is jeet se jura hai, to50 him desh will or world top in position. (en)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for translation in translations:\n",
        "   print(f\"{translation.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J_hUDJrQwXT",
        "outputId": "71d3886f-d6b3-4c74-84b1-94a9dcc64b69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@narendramodi great congress sir, you were sent by mother India\n",
            "Lord Krishna and Ram wrote Asan Avatar, for the welfare of the country.\n",
            "Saos krode desh bashio ki umid is jeet se jura hai, to50 him desh will or world top in position.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text ='''yeh tho biographical movie ke tarah hein, mark zukerberk ke baare mein hein kya. \n",
        "jo facebook create kiya haan yar. '''"
      ],
      "metadata": {
        "id": "0lp8mkbZChNU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " text ='''@narendramodi great congratulations Sir,  \n",
        " ap ko Bharat Mata ne bheja, as an avtar like Lord Krishna and Ram, \n",
        " desh ke Kalman ke liye. Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world Top in position. '''"
      ],
      "metadata": {
        "id": "7Cyb4sppHUfm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [text]\n",
        "translations = translator.translate(sentences, dest=\"en\")\n",
        "for translation in translations:\n",
        "    print(f\"{translation.origin} ({translation.src}) -->\\n {translation.text} ({translation.dest})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVy9tm5TVbQJ",
        "outputId": "c2b4f4fd-ae5d-4d3a-a54f-b346af788ff0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@narendramodi great congratulations Sir,  \n",
            "ap ko Bharat Mata ne bheja, as an avtar like Lord Krishna and Ram, \n",
            "desh ke Kalman ke liye. Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world Top in position.  (hi) -->\n",
            " @narendramodi great congratulations Sir,\n",
            "ap ko Bharat Mata ne bheja, as an avtar like Lord Krishna and Ram,\n",
            "desh ke Kalman ke liye. Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world top in position. (en)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translation.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNNf5SitHK4C",
        "outputId": "02aa49c9-44cb-4857-f8b6-ba562f23e0d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@narendramodi great congratulations Sir,\n",
            "ap ko Bharat Mata ne bheja, as an avtar like Lord Krishna and Ram,\n",
            "desh ke Kalman ke liye. Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world top in position.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(translation.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3yJ-xIONsve",
        "outputId": "df828554-2284-4491-80a0-c05f98707a21"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data is :%s\" % (translation.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGw669vdOkh3",
        "outputId": "7910364d-e516-4a25-d742-775fc56a1b3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is :@narendramodi great congratulations Sir,\n",
            "ap ko Bharat Mata ne bheja, as an avtar like Lord Krishna and Ram,\n",
            "desh ke Kalman ke liye. Soaoso crore desh bashio ki umid iss jit se Jura hay,2050 tak desh will be world top in position.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizer\n",
        "Here we have given text and the model will summarize the text. We have already converted text in english language using translator in the above part. Here the model can summarize upto huge scale of data at once."
      ],
      "metadata": {
        "id": "jKDOXpwWg9zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from heapq import nlargest\n",
        "\n",
        "text = \"\"\" \n",
        "This story is part of a group of stories called\n",
        "Finding the best ways to do good.\n",
        "\n",
        "On October 27, Valentin Bruttel, a molecular immunologist at the University of Wurzburg, Germany, and co-authors Alex Washburne and Antonius VanDongen released a preprint — a scientific paper that has not yet gone through the process of peer review — with a shocking claim: The original SARS-CoV-2 coronavirus that caused the Covid-19 pandemic did not emerge in animals and jump over to humans, as most scientists assume, but had most likely been synthesized in a lab. And they had developed statistical tests that they said backed up their claim.\n",
        "\n",
        "This was an all-time “big if true” claim. The ultimate origins of Covid are one of the biggest open questions in science, and if clear evidence emerged that a pandemic that has killed millions began with the work of researchers in a lab, the ramifications for science would be unimaginable.\n",
        "\n",
        "I have now spent much of the last week looking into the work of Bruttel and his colleagues, and I think their analysis doesn’t hold up — meaning the paper doesn’t help resolve the question of how SARS-CoV-2 originated.\n",
        "\n",
        "But while usually I wouldn’t bother writing about a preprint that doesn’t stand up to in-depth scrutiny and may never be peer reviewed and fully published at all — for one thing, there have been tens of thousands of preprints on Covid alone — in this case I think it’s worth it. That’s because the researchers’ original claim circulated widely and is worth thoughtfully answering, and because the preprint and the response represent both the best and the worst in how our scientific institutions and processes converge on truth.\n",
        "\n",
        "First, some biology\n",
        "Everything made out of RNA — including SARS-CoV-2 — is made up of strings of four nucleotides: adenine (A), uracil (U), guanine (G), and cytosine (C). There are about 30,000 of these nucleotides in the genome for SARS-CoV-2. Given how small the genetic alphabet is, that means lots of short strings of nucleotides will recur over and over just by coincidence.\n",
        "\n",
        "When researchers are conducting lab work on viruses, they take advantage of certain short strings, called restriction sites, that appear repeatedly in the genome. Those strings will bind to certain enzymes the researchers use to cut and glue segments of the virus, which enables them to assemble whole genomes from short sequences, swap out different sequences to study different things, and more.\n",
        "\n",
        "Sign up for the newsletter Future Perfect\n",
        "Each week, we explore unique solutions to some of the world's biggest problems.\n",
        "\n",
        "Email (required)\n",
        "By submitting your email, you agree to our Terms and Privacy Notice. You can opt out at any time. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. For more newsletters, check out our newsletters page.\n",
        "There are many different ways to do cutting and gluing work in viruses — different enzymes to use, different details of how to employ them. The researchers in the preprint argue that coronavirus research at labs — including the Wuhan Institute of Virology in 2017, 2018, and 2019 — involved working with two specific enzymes and adding restriction sites in strategic locations in order to enable further work. They then go on to claim that the genome for SARS-CoV-2 has unusually evenly spaced restriction sites, along with a few other characteristics, that statistical analysis suggests would be more likely to be the product of lab synthesis rather than the randomness of natural evolution.\n",
        "\n",
        "This is an interesting approach, and I’m excited about the general concept of identifying the genetic fingerprints of synthesized viruses, given that the risk from engineered viruses will only rise in the future. But after talking to researchers in virology, microbiology, and comparative genomics, I don’t think the restriction site patterns in SARS-Cov-2 are suspicious.\n",
        "\n",
        "Viruses recombine with each other constantly, sharing chunks of their genetic code each time. Each of the restriction sites identified in the paper is present in other SARS-CoV-2-like coronaviruses researchers have identified in the last few years. Critically, the sequences around the restriction site in SARS-CoV-2 also tend to match the surrounding RNA in the other coronaviruses —suggesting that the whole segment was lifted into SARS-CoV-2 all at once.\n",
        "\n",
        "“This would have to imply that someone not only modified the RE [restriction] sites to match natural viruses, but also unrelated nearby sites as well — but it is unclear to me why anyone would do such a thing,” Alex Crits-Christoph, a genomics researcher at Johns Hopkins University, told me. And even if some researcher did do that for some reason, the statistical analyses in this paper wouldn’t detect it — they only make sense if you assume a different virus-synthesis strategy.\n",
        "\n",
        "That doesn’t settle the question of the origins of Covid, of course. When I talked to Washburne, he pointed out that it’s possible these coronaviruses could have been recombined in a lab. But it means that this paper — which drew statistical inferences from the idea that a particular cloning strategy was used to modify the virus — doesn’t explain anything that needs explaining.\n",
        "\n",
        "Even scientists who think a synthetic origin for Covid-19 is a very real possibility — such as Alina Chan, a molecular biologist at the Broad Institute of MIT and Harvard who has made the case we need a full investigation to determine whether Covid was naturally or synthetically occurring — told me they thought this paper couldn’t prove the strong claim it was making.\n",
        "\n",
        "Next, some meta-science\n",
        "So, that’s the answer — which scientific debate on the open internet arrived at quite quickly. At times, though, the process of getting there was a bit ugly.\n",
        "\n",
        "While some researchers started out intrigued by the paper, others argued it was not just wrong but obviously, blatantly wrong — “poppycock dressed up as science, with a heavy dose of technobabble on the side,” Kristian G. Andersen, an immunologist at the Scripps Research Institute in San Diego, tweeted, adding, “it wouldn’t pass kindergarten molecular biology.” (As the parent of a kindergartener, I think he may be overestimating the rigor of our molecular biology curriculum.)\n",
        "\n",
        "One of the few well-respected scientists who defended the paper deleted his Twitter account after an uproar. Washburne, one of the authors, posted his entire academic history in response to allegations he’s a fraud who didn’t actually have a PhD. (He does, in fact, from Princeton.)\n",
        "\n",
        "Obviously, it’s frustrating to be a scientist when a flawed preprint is released and circulates widely, including a skeptical but serious treatment in the Economist, while the details of why it’s unconvincing are hard to explain. It’s understandably exasperating to scientists that it takes far more effort to refute work than to put it out there in the first place, and it’s shocking how far a piece can travel by the time researchers look into it more closely.\n",
        "\n",
        "The Covid origins debate in particular has been suffused with such advocacy through preprints. This spring, the same thing happened for the other side: A New York Times feature article was timed to the release of a preprint making the case for natural origins, to the chagrin of scientists who felt the New York Times should have waited until there’d been more scientific engagement with the study. Substantial changes were made to the scientific study in the course of the peer review process, and the peer commentary process is still ongoing, but most of the audience doesn’t follow the peer review process. They just read the New York Times.\n",
        "\n",
        "Does that mean we should give up on preprints (or at least that we, the media, should refrain from publishing articles about them)? I’m not quite sure. Firstly, peer-reviewed articles can also be blatantly flawed and full of holes. To write about science, you have to do due diligence; whether an article is a preprint or not can affect your calculus, but it shouldn’t be the sole determinant.\n",
        "\n",
        "Secondly, the conversation about lab origins has taken on a distinctly conspiratorial bent. Many of those who believe that Covid originated in a lab also believe that the scientific community has organized to suppress the proof and punish anyone who speaks it. To counter that, sunlight really is the best disinfectant.\n",
        "\n",
        "I reached out to many different researchers to understand this paper, and I think the people worried that lab origins are being unduly suppressed would be cheered by what I heard. Researchers gave initial impressions, read the paper, and refined their initial impressions. Some of them developed their own quick tests of the robustness of the statistical conclusions. People tweeted graphs, arguments, counterarguments, and yes, the occasional insult. We all got to see how the sausage got made, and honestly, it wasn’t that gross.\n",
        "\n",
        "For all the social media furor, in this case I think that our scientific process basically did its job — which meant determining that this paper doesn’t really move our understanding of Covid origins. In the ages before preprint servers, all this anger and all the insults — but also all of this genuine truth-seeking and intellectual curiosity — would have happened behind closed doors. I’m not very sorry it now happens in the open instead — though I do think journalists have a lot of work to do to make sure that the truth can catch up with rumors. \"\"\"\n",
        "\n",
        "#translaterator word by word\n",
        "stopwords = list(STOP_WORDS)\n",
        "nlp = spacy.load('en_core_web_sm') #\"\"\" edit spacy / download\"\"\"\n",
        "doc = nlp(text)\n",
        "tokens = [token.text for token in doc]\n",
        "#print(tokens)\n",
        "punctuation = punctuation + '\\n'\n",
        "word_frequencies = {}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stopwords:\n",
        "        if word.text.lower() not in punctuation:\n",
        "            if word.text not in word_frequencies.keys():\n",
        "                word_frequencies[word.text] = 1\n",
        "            else:\n",
        "                word_frequencies[word.text] += 1\n",
        "max_frequency = max(word_frequencies.values())\n",
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] = word_frequencies[word]/max_frequency\n",
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "sentence_scores = {}\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "        if word.text.lower() in word_frequencies.keys():\n",
        "            if sent not in sentence_scores.keys():\n",
        "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "            else:\n",
        "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "            select_length = int(len(sentence_tokens)*0.3)\n",
        "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
        "final_summary = [word.text for word in summary]\n",
        "summary = ' '.join(final_summary)\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mbbc8cLaAns",
        "outputId": "dbdb157b-b5d5-4593-9385-31c68396e293"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On October 27, Valentin Bruttel, a molecular immunologist at the University of Wurzburg, Germany, and co-authors Alex Washburne and Antonius VanDongen released a preprint — a scientific paper that has not yet gone through the process of peer review — with a shocking claim: The original SARS-CoV-2 coronavirus that caused the Covid-19 pandemic did not emerge in animals and jump over to humans, as most scientists assume, but had most likely been synthesized in a lab. Even scientists who think a synthetic origin for Covid-19 is a very real possibility — such as Alina Chan, a molecular biologist at the Broad Institute of MIT and Harvard who has made the case we need a full investigation to determine whether Covid was naturally or synthetically occurring — told me they thought this paper couldn’t prove the strong claim it was making.\n",
            "\n",
            " The researchers in the preprint argue that coronavirus research at labs — including the Wuhan Institute of Virology in 2017, 2018, and 2019 — involved working with two specific enzymes and adding restriction sites in strategic locations in order to enable further work. While some researchers started out intrigued by the paper, others argued it was not just wrong but obviously, blatantly wrong — “poppycock dressed up as science, with a heavy dose of technobabble on the side,” Kristian G. Andersen, an immunologist at the Scripps Research Institute in San Diego, tweeted, adding, “it wouldn’t pass kindergarten molecular biology.” But while usually I wouldn’t bother writing about a preprint that doesn’t stand up to in-depth scrutiny and may never be peer reviewed and fully published at all — for one thing, there have been tens of thousands of preprints on Covid alone — in this case I think it’s worth it. I have now spent much of the last week looking into the work of Bruttel and his colleagues, and I think their analysis doesn’t hold up — meaning the paper doesn’t help resolve the question of how SARS-CoV-2 originated.\n",
            "\n",
            " And even if some researcher did do that for some reason, the statistical analyses in this paper wouldn’t detect it — they only make sense if you assume a different virus-synthesis strategy.\n",
            "\n",
            " Those strings will bind to certain enzymes the researchers use to cut and glue segments of the virus, which enables them to assemble whole genomes from short sequences, swap out different sequences to study different things, and more.\n",
            "\n",
            " But it means that this paper — which drew statistical inferences from the idea that a particular cloning strategy was used to modify the virus — doesn’t explain anything that needs explaining. That’s because the researchers’ original claim circulated widely and is worth thoughtfully answering, and because the preprint and the response represent both the best and the worst in how our scientific institutions and processes converge on truth.\n",
            "\n",
            " For all the social media furor, in this case I think that our scientific process basically did its job — which meant determining that this paper doesn’t really move our understanding of Covid origins. They then go on to claim that the genome for SARS-CoV-2 has unusually evenly spaced restriction sites, along with a few other characteristics, that statistical analysis suggests would be more likely to be the product of lab synthesis rather than the randomness of natural evolution.\n",
            "\n",
            " “This would have to imply that someone not only modified the RE [restriction] sites to match natural viruses, but also unrelated nearby sites as well — but it is unclear to me why anyone would do such a thing,” Alex Crits-Christoph, a genomics researcher at Johns Hopkins University, told me. In the ages before preprint servers, all this anger and all the insults — but also all of this genuine truth-seeking and intellectual curiosity — would have happened behind closed doors. There are many different ways to do cutting and gluing work in viruses — different enzymes to use, different details of how to employ them. Critically, the sequences around the restriction site in SARS-CoV-2 also tend to match the surrounding RNA in the other coronaviruses —suggesting that the whole segment was lifted into SARS-CoV-2 all at once.\n",
            "\n",
            " It’s understandably exasperating to scientists that it takes far more effort to refute work than to put it out there in the first place, and it’s shocking how far a piece can travel by the time researchers look into it more closely.\n",
            "\n",
            " First, some biology\n",
            "Everything made out of RNA — including SARS-CoV-2 — is made up of strings of four nucleotides: adenine (A), uracil (U), guanine (G), and cytosine (C).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsSrOAA7f-fy"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}